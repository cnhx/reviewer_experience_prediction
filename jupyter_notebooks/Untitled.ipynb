{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "from bs4 import (BeautifulSoup,\n",
    "                 UnicodeDammit)\n",
    "\n",
    "# Define a couple useful regular expressions\n",
    "SPACE = re.compile(r'[\\s]+')\n",
    "BREAKS_REGEX = re.compile(r'\\<br\\>')\n",
    "COMMA = re.compile(r',')\n",
    "\n",
    "# Codecs for use with UnicodeDammit\n",
    "codecs = [\"windows-1252\", \"utf8\", \"ascii\", \"cp500\", \"cp850\", \"cp852\",\n",
    "          \"cp858\", \"cp1140\", \"cp1250\", \"iso-8859-1\", \"iso8859_2\",\n",
    "          \"iso8859_15\", \"iso8859_16\", \"mac_roman\", \"mac_latin2\", \"utf32\",\n",
    "          \"utf16\"]\n",
    "\n",
    "def get_review_data_for_game(appid, time_out=0.5, limit=0, sleep=10):\n",
    "    '''\n",
    "    Generate dictionaries for each review for a given game.\n",
    "\n",
    "    The dictionaries will contain keys for the review text, the reviewer ID,\n",
    "    the reviewer's user-name, the number of friends the reviewer has, the\n",
    "    the number of reviews the reviewer has written, and much more.\n",
    "\n",
    "    :param appid: ID corresponding to a given game\n",
    "    :type appid: str\n",
    "    :param timeout: amount of time allowed to go by without hearing\n",
    "                    response while using requests.get() method\n",
    "    :type timeout: float\n",
    "    :param limit: the maximum number of reviews to collect\n",
    "    :type limit: int (default: 0, which signifies all)\n",
    "    :param sleep: amount of time to wait between reading different pages on\n",
    "                  Steam\n",
    "    :type sleep: int/float\n",
    "    :yields: dictionary with keys for various pieces of data related to a\n",
    "             single review, including the review itself, the number of hours\n",
    "             the reviewer has played the game, etc.\n",
    "    '''\n",
    "\n",
    "    if limit == 0:\n",
    "        limit = -1\n",
    "    range_begin = 0\n",
    "    i = 1\n",
    "    reviews_count = 0\n",
    "    while True:\n",
    "        # Get unique URL for values of range_begin and i\n",
    "        base_url = 'http://steamcommunity.com/app/{2}/homecontent/?user' \\\n",
    "                   'reviewsoffset={0}&p=1&itemspage={1}&screenshotspage' \\\n",
    "                   '={1}&videospage={1}&artpage={1}&allguidepage={1}&web' \\\n",
    "                   'guidepage={1}&integratedguidepage={1}&discussionspage' \\\n",
    "                   '={1}&appid={2}&appHubSubSection=10&appHubSubSection=' \\\n",
    "                   '10&l=english&browsefilter=toprated&filterLanguage=' \\\n",
    "                   'default&searchText=&forceanon=1'.format(range_begin,\n",
    "                                                            i,\n",
    "                                                            appid)\n",
    "        # Get the URL content\n",
    "        base_page = None\n",
    "        time.sleep(sleep)\n",
    "        # Get the HTML page; if there's a timeout error, then catch it and\n",
    "        # exit out of the loop, effectively ending the function.\n",
    "        try:\n",
    "            base_page = requests.get(base_url,\n",
    "                                     timeout=time_out)\n",
    "        except requests.exceptions.Timeout as e:\n",
    "            print(\"There was a Timeout error...\")\n",
    "            break\n",
    "        # If there's nothing at this URL, page might have no value at all,\n",
    "        # in which case we should break out of the loop\n",
    "        # Another situation where we'd want to exit from the loop is if the\n",
    "        # page.text contains only an empty string or a string that has only\n",
    "        # a sequence of one or more spaces\n",
    "        if not base_page:\n",
    "            break\n",
    "        elif not base_page.text.strip():\n",
    "            break\n",
    "        # Preprocess the HTML source, getting rid of \"<br>\" tags and\n",
    "        # replacing any sequence of one or more carriage returns or\n",
    "        # whitespace characters with a single space\n",
    "        base_html = SPACE.sub(r' ',\n",
    "                              BREAKS_REGEX.sub(r' ',\n",
    "                                               base_page.text.strip()))\n",
    "        # Try to decode the HTML to unicode and then re-encode the text\n",
    "        # with ASCII, ignoring any characters that can't be represented\n",
    "        # with ASCII\n",
    "        base_html = UnicodeDammit(base_html,\n",
    "                                  codecs).unicode_markup.encode('ascii',\n",
    "                                                                'ignore')\n",
    "\n",
    "        # Parse the source HTML with BeautifulSoup\n",
    "        source_soup = BeautifulSoup(base_html,\n",
    "                                    'lxml')\n",
    "        reviews = source_soup.find_all('div',\n",
    "                                'apphub_Card interactable') #Change soup -> source_soup\n",
    "\n",
    "        # Iterate over the reviews in the source HTML and find data for\n",
    "        # each review, yielding a dictionary\n",
    "        for review in reviews:\n",
    "\n",
    "            # Get links to review URL, profile URL, Steam ID number\n",
    "            review_url = review.attrs['onclick'].split(' ',\n",
    "                                                       2)[1].strip(\"',\")\n",
    "            review_url_split = review_url.split('/')\n",
    "            steam_id_number = review_url_split[4]\n",
    "            profile_url = '/'.join(review_url_split[:5])\n",
    "\n",
    "            # Get other data within the base reviews page\n",
    "            stripped_strings = list(review.stripped_strings)\n",
    "            # Parsing the HTML in this way depends on stripped_strings\n",
    "            # having a length of at least 8\n",
    "            if len(stripped_strings) >= 8:\n",
    "                print(stripped_strings)\n",
    "                # Extracting data from the text that supplies the number\n",
    "                # of users who found the review helpful and/or funny\n",
    "                # depends on a couple facts\n",
    "                helpful_and_funny_list = stripped_strings[0].split()\n",
    "                if (helpful_and_funny_list[8] == 'helpful'\n",
    "                    and len(helpful_and_funny_list) == 15):\n",
    "                    helpful = helpful_and_funny_list[:9]\n",
    "                    funny = helpful_and_funny_list[9:]\n",
    "                    num_found_helpful = int(COMMA.sub(r'',\n",
    "                                                  helpful[0]))\n",
    "                    num_voted_helpfulness = int(COMMA.sub(r'',\n",
    "                                                          helpful[2]))\n",
    "                    num_found_unhelpful = \\\n",
    "                        num_voted_helpfulness - num_found_helpful\n",
    "                    found_helpful_percentage = \\\n",
    "                        float(num_found_helpful)/num_voted_helpfulness\n",
    "                    num_found_funny = funny[0]\n",
    "                recommended = stripped_strings[1]\n",
    "                total_game_hours = COMMA.sub(r'',\n",
    "                                             stripped_strings[2]\n",
    "                                             .split()[0])\n",
    "                date_posted = '{}, 2015'.format(stripped_strings[3][8:])\n",
    "                review_text = ' '.join(stripped_strings[4:-3])\n",
    "                num_games_owned = stripped_strings[-2].split()[0]\n",
    "            else:\n",
    "                sys.stderr.write('Found incorrect number of '\n",
    "                                 '\"stripped_strings\" in review HTML '\n",
    "                                 'element. stripped_strings: {}\\n'\n",
    "                                 'Continuing.'\n",
    "                                 .format(stripped_strings))\n",
    "                continue\n",
    "\n",
    "            # Make dictionary for holding all the data related to the\n",
    "            # review\n",
    "            review_dict = \\\n",
    "                dict(review_url=review_url,\n",
    "                     recommended=recommended,\n",
    "                     total_game_hours=total_game_hours,\n",
    "                     date_posted=date_posted,\n",
    "                     review=review_text,\n",
    "                     num_games_owned=num_games_owned,\n",
    "                     num_found_helpful=num_found_helpful,\n",
    "                     num_found_unhelpful=num_found_unhelpful,\n",
    "                     num_voted_helpfulness=num_voted_helpfulness,\n",
    "                     found_helpful_percentage=found_helpful_percentage,\n",
    "                     num_found_funny=num_found_funny,\n",
    "                     steam_id_number=steam_id_number,\n",
    "                     profile_url=profile_url)\n",
    "\n",
    "            # Follow links to profile and review pages and collect data\n",
    "            # from there\n",
    "            time.sleep(sleep)\n",
    "            review_page = requests.get(review_dict['review_url'])\n",
    "            time.sleep(sleep)\n",
    "            profile_page = requests.get(review_dict['profile_url'])\n",
    "            review_page_html = review_page.text\n",
    "            profile_page_html = profile_page.text\n",
    "\n",
    "            # Preprocess HTML and try to decode the HTML to unicode and\n",
    "            # then re-encode the text with ASCII, ignoring any characters\n",
    "            # that can't be represented with ASCII\n",
    "            review_page_html = \\\n",
    "                SPACE.sub(r' ',\n",
    "                          BREAKS_REGEX.sub(r' ',\n",
    "                                           review_page_html.strip()))\n",
    "            review_page_html = \\\n",
    "                UnicodeDammit(review_page_html,\n",
    "                              codecs).unicode_markup.encode('ascii',\n",
    "                                                            'ignore')\n",
    "            profile_page_html = \\\n",
    "                SPACE.sub(r' ',\n",
    "                          BREAKS_REGEX.sub(r' ',\n",
    "                                           profile_page_html.strip()))\n",
    "            profile_page_html = \\\n",
    "                UnicodeDammit(profile_page_html,\n",
    "                              codecs).unicode_markup.encode('ascii',\n",
    "                                                            'ignore')\n",
    "\n",
    "            # Now use BeautifulSoup to parse the HTML\n",
    "            review_soup = BeautifulSoup(review_page_html,\n",
    "                                        'lxml')\n",
    "            profile_soup = BeautifulSoup(profile_page_html,\n",
    "                                         'lxml')\n",
    "\n",
    "            # Get the user-name from the review page\n",
    "            review_dict['username'] = \\\n",
    "                review_soup.find('span',\n",
    "                                 'profile_small_header_name').string\n",
    "\n",
    "            # Get the number of hours the reviewer played the game in the\n",
    "            # last 2 weeks\n",
    "            review_dict['hours_previous_2_weeks'] = \\\n",
    "                COMMA.sub(r'',\n",
    "                          review_soup.find('div',\n",
    "                                           'playTime').string.split()[0])\n",
    "\n",
    "            # Get the number of comments users made on the review (if any)\n",
    "            review_dict['num_comments'] = \\\n",
    "                COMMA.sub(r'',\n",
    "                          list(review_soup\n",
    "                               .find('div',\n",
    "                                     'commentthread_count')\n",
    "                               .strings)[1])\n",
    "\n",
    "            # Get the reviewer's \"level\" (friend player level)\n",
    "            friend_player_level = profile_soup.find('div',\n",
    "                                                    'friendPlayerLevel')\n",
    "            if friend_player_level:\n",
    "                review_dict['friend_player_level'] = \\\n",
    "                    friend_player_level.string\n",
    "            else:\n",
    "                review_dict['friend_player_level'] = None\n",
    "\n",
    "            # Get the game achievements summary data\n",
    "            achievements = \\\n",
    "                profile_soup.find('span',\n",
    "                                  'game_info_achievement_summary')\n",
    "            if achievements:\n",
    "                achievements = achievements.stripped_strings\n",
    "                if achievements:\n",
    "                    achievements = list(achievements)[1].split()\n",
    "                    review_dict['achievement_progress'] = \\\n",
    "                        dict(num_achievements_attained=achievements[0],\n",
    "                             num_achievements_possible=achievements[2])\n",
    "                else:\n",
    "                    review_dict['achievement_progress'] = \\\n",
    "                        dict(num_achievements_attained=None,\n",
    "                             num_achievements_possible=None)\n",
    "            else:\n",
    "                review_dict['achievement_progress'] = \\\n",
    "                    dict(num_achievements_attained=None,\n",
    "                         num_achievements_possible=None)\n",
    "\n",
    "            # Get the number of badges the reviewer has earned on the site\n",
    "            badges = profile_soup.find('div',\n",
    "                                       'profile_badges')\n",
    "            if badges:\n",
    "                badges = badges.stripped_strings\n",
    "                if badges:\n",
    "                    review_dict['num_badges'] = list(badges)[1]\n",
    "                else:\n",
    "                    review_dict['num_badges'] = None\n",
    "            else:\n",
    "                review_dict['num_badges'] = None\n",
    "\n",
    "            # Get the number of reviews the reviewer has written across all\n",
    "            # games and the number of screenshots he/she has taken\n",
    "            reviews_screens = profile_soup.find('div',\n",
    "                                                'profile_item_links')\n",
    "            if reviews_screens:\n",
    "                reviews_screens = reviews_screens.stripped_strings\n",
    "                if reviews_screens:\n",
    "                    reviews_screens = list(reviews_screens)\n",
    "                    review_dict['num_screenshots'] = reviews_screens[3]\n",
    "                    review_dict['num_reviews'] = reviews_screens[5]\n",
    "                else:\n",
    "                    review_dict['num_screenshots'] = None\n",
    "                    review_dict['num_reviews'] = None\n",
    "            else:\n",
    "                review_dict['num_screenshots'] = None\n",
    "                review_dict['num_reviews'] = None\n",
    "\n",
    "            # Get the number of groups the reviewer is part of on the site\n",
    "            groups = profile_soup.find('div',\n",
    "                                       'profile_group_links')\n",
    "            if groups:\n",
    "                groups = groups.stripped_strings\n",
    "                if groups:\n",
    "                    review_dict['num_groups'] = list(groups)[1]\n",
    "                else:\n",
    "                    review_dict['num_groups'] = None\n",
    "            else:\n",
    "                review_dict['num_groups'] = None\n",
    "\n",
    "            # Get the number of friends the reviwer has on the site\n",
    "            friends = profile_soup.find('div',\n",
    "                                        'profile_friend_links')\n",
    "            if friends:\n",
    "                friends = friends.stripped_strings\n",
    "                if friends:\n",
    "                    review_dict['num_friends'] = list(friends)[1]\n",
    "                else:\n",
    "                    review_dict['num_friends'] = None\n",
    "            else:\n",
    "                review_dict['num_friends'] = None\n",
    "\n",
    "            yield review_dict\n",
    "\n",
    "            reviews_count += 1\n",
    "            if reviews_count == limit:\n",
    "                break\n",
    "\n",
    "        if reviews_count == limit:\n",
    "            break\n",
    "\n",
    "        # Increment the range_begin and i variables, which will be used in\n",
    "        # the generation of the next page of reviews\n",
    "        range_begin += 10\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [review for review in get_review_data_for_game('570',\n",
    "                                                         time_out=3,\n",
    "                                                         limit=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
